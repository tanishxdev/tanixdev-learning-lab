# PROBLEM (Original Statement)

[Problem](https://leetcode.com/problems/remove-duplicates-from-sorted-array/)
Given an integer array nums sorted in non-decreasing order, remove the duplicates in-place such that each unique element appears only once. The relative order of the elements should be kept the same.

Consider the number of unique elements in nums to be k. After removing duplicates, return the number of unique elements k.

The first k elements of nums should contain the unique numbers in sorted order. The remaining elements beyond index k - 1 can be ignored.

Custom Judge:

The judge will test your solution with the following code:

int[] nums = [...]; // Input array
int[] expectedNums = [...]; // The expected answer with correct length

int k = removeDuplicates(nums); // Calls your implementation

assert k == expectedNums.length;
for (int i = 0; i < k; i++) {
    assert nums[i] == expectedNums[i];
}
If all assertions pass, then your solution will be accepted.

Example 1:

Input: nums = [1,1,2]
Output: 2, nums = [1,2,_]
Explanation: Your function should return k = 2, with the first two elements of nums being 1 and 2 respectively.
It does not matter what you leave beyond the returned k (hence they are underscores).

Example 2:

Input: nums = [0,0,1,1,1,2,2,3,3,4]
Output: 5, nums = [0,1,2,3,4,_,_,_,_,_]
Explanation: Your function should return k = 5, with the first five elements of nums being 0, 1, 2, 3, and 4 respectively.
It does not matter what you leave beyond the returned k (hence they are underscores).

Constraints:

1 <= nums.length <= 3 * 10^4
-100 <= nums[i] <= 100
nums is sorted in non-decreasing order.

---

## BREAKDOWN PROBLEM

You are given a sorted array in non-decreasing order. You must remove duplicate elements from the array. You cannot use extra space - you must modify the array in-place. The first k positions of the array should contain all unique elements in sorted order. You need to return k, which is the count of unique elements. The elements beyond index k-1 don't matter.

---

## CONSTRAINT UNDERSTANDING

- Array length: 1 to 30,000 elements
- Values: -100 to 100
- Array is sorted in non-decreasing order (duplicates are adjacent)
- Must do it in-place with O(1) extra memory
- Must maintain sorted order of unique elements

Constraints tell us:
- Cannot use extra array or data structures that take O(n) space
- Since array is sorted, duplicates are next to each other - we can scan and compare adjacent elements
- n can be up to 30,000, so O(n^2) is too slow, but O(n) is fine

---

# BRUTE FORCE APPROACH

## First Thought Intuition

First natural idea: "Let me build a new array and push only unique values." Loop over the original array, check if current element is different from last added element, if yes, push to new array. Then copy back to original array.

## Thought Process (Step-wise)

1. Create empty result array
2. Add first element to result array
3. For each subsequent element in nums:
   - Compare with last element in result array
   - If different, add to result array
4. Copy all elements from result array back to nums
5. Return size of result array

## Pseudocode
result = []
result.push(nums[0])

for i = 1 to nums.length-1:
    if nums[i] != result[last_index]:
        result.push(nums[i])

for i = 0 to result.length-1:
    nums[i] = result[i]

return result.length

## Algorithm
1. Initialize an empty result array
2. Add the first element of nums to result
3. Iterate through nums from index 1 to end
4. For each element, compare with last element in result
5. If different, append to result
6. Copy result back to nums
7. Return length of result

## CODE (C++ and JavaScript)

### C++

#### V1 (Only Required Function)
```cpp
int removeDuplicates(vector<int>& nums) {
    vector<int> result;
    result.push_back(nums[0]);
    
    for(int i = 1; i < nums.size(); i++) {
        if(nums[i] != result.back()) {
            result.push_back(nums[i]);
        }
    }
    
    for(int i = 0; i < result.size(); i++) {
        nums[i] = result[i];
    }
    
    return result.size();
}
```

#### V2 (Complete Program)
```cpp
#include <bits/stdc++.h>
using namespace std;

int removeDuplicates(vector<int>& nums) {
    if(nums.size() == 0) return 0;
    
    vector<int> result;
    result.push_back(nums[0]);
    
    for(int i = 1; i < nums.size(); i++) {
        if(nums[i] != result.back()) {
            result.push_back(nums[i]);
        }
    }
    
    for(int i = 0; i < result.size(); i++) {
        nums[i] = result[i];
    }
    
    return result.size();
}

int main() {
    vector<int> nums = {1, 1, 2, 2, 3};
    
    int k = removeDuplicates(nums);
    
    cout << "Unique count = " << k << endl;
    cout << "Array after removing duplicates:\n";
    
    for(int i = 0; i < k; i++) {
        cout << nums[i] << " ";
    }
    
    return 0;
}
```

### JavaScript

#### V1 (Only Required Function)
```javascript
var removeDuplicates = function(nums) {
    let result = [nums[0]];
    
    for(let i = 1; i < nums.length; i++) {
        if(nums[i] !== result[result.length - 1]) {
            result.push(nums[i]);
        }
    }
    
    for(let i = 0; i < result.length; i++) {
        nums[i] = result[i];
    }
    
    return result.length;
};
```

#### V2 (Complete Program)
```javascript
function removeDuplicates(nums) {
    let result = [nums[0]];
    
    for(let i = 1; i < nums.length; i++) {
        if(nums[i] !== result[result.length - 1]) {
            result.push(nums[i]);
        }
    }
    
    for(let i = 0; i < result.length; i++) {
        nums[i] = result[i];
    }
    
    return result.length;
}

// Test
let nums = [1, 1, 2, 2, 3];
let k = removeDuplicates(nums);

console.log("Unique count:", k);
console.log("Array:", nums.slice(0, k));
```

## Time and Space Complexity
Time Complexity: O(n) - we iterate through array twice (once to build result, once to copy back)
Space Complexity: O(n) - we create a new result array that can hold up to n elements

## Dry Run (All Cases)

Normal Case: nums = [1, 1, 2, 2, 3]
1. result = [1]
2. i=1: 1 == 1, skip
3. i=2: 2 != 1, result = [1, 2]
4. i=3: 2 == 2, skip
5. i=4: 3 != 2, result = [1, 2, 3]
6. Copy back: nums = [1, 2, 3, 2, 3]
7. Return 3

Best Case: nums = [1, 2, 3] (already unique)
1. result = [1]
2. i=1: 2 != 1, result = [1, 2]
3. i=2: 3 != 2, result = [1, 2, 3]
4. Copy back
5. Return 3

Worst Case: nums = [1, 1, 1, 1, 1] (all duplicates)
1. result = [1]
2. All other elements equal to 1, so none added
3. result = [1]
4. Copy back
5. Return 1

## Edge Cases
1. Single element array: nums = [5] → result = [5], return 1
2. Empty array: Need to handle separately (but constraints say min length is 1)
3. All same elements: Works as shown above
4. Already unique array: Works as shown above
5. Negative numbers: nums = [-2, -2, -1, 0, 0, 1] → Works fine

## How This Approach Handles the Problem
This approach correctly identifies and collects all unique elements while maintaining sorted order. It uses the fact that array is sorted - we only compare with last added element.

## Does This Approach Fail?

YES

Where: Space complexity constraint

Why: Uses O(n) extra space for result array

Which constraint breaks it: The problem requires in-place modification with O(1) extra memory. Creating a new array violates this constraint.

---

# WRONG APPROACH (Using Set)

## First Thought Intuition

"I can use a set to automatically remove duplicates. Insert all elements into a set, then copy unique elements back to front of array."

## Thought Process (Step-wise)

1. Create unordered_set from array elements
2. This automatically removes duplicates
3. Copy elements from set back to array starting from index 0
4. Return size of set

## My Wrong Code
```cpp
class Solution {
public:
    int removeDuplicates(vector<int>& nums) {
        unordered_set<int> s(nums.begin(), nums.end());
        int k = 0;
        
        for (int x : s) {
            nums[k++] = x;
        }
        
        return k;
    }
};
```

## Why This Approach Was Wrong

1. **Destroys sorted order**: unordered_set doesn't preserve any order. Even ordered_set would sort differently.
2. **Uses extra memory**: Set takes O(n) space, violating in-place requirement.
3. **Doesn't exploit sorted property**: The array is already sorted - using set ignores this advantage.

## Mental Mistake

Thinking: "Unique nikalna hai, toh set bana leta hoon." This is data-cleaning mindset, not algorithmic thinking. The problem tests if you can exploit the sorted property to work in-place.

## Interview Truth

This solution would be rejected in FAANG interviews because:
- Breaks O(1) space requirement
- Breaks sorted order guarantee
- Doesn't demonstrate understanding of pointer manipulation

---

# WRONG APPROACH (Mixed Pointer Logic)

## My Initial Wrong Thinking

```cpp
class Solution {
public:
    int removeDuplicates(vector<int>& nums) {
        int i = 0;
        
        for(int j = i; i<nums.size(); i++)
        {
            if(arr[i] == arr[j])
            {
                j++
            } else {
                i = j;
                i++
            }

            return 
        }
    }
};
```

## Why This Code Was Wrong

1. **Mixed i and j roles**: Didn't assign clear roles to pointers
2. **Wrong loop condition**: Using i in condition but j is the scanner
3. **Incomplete return statement**: Missing return value
4. **Wrong variable name**: Using arr instead of nums
5. **Logic confusion**: Trying to move both pointers without clear strategy

## My Confusion

I didn't understand:
- Which pointer should track unique position
- Which pointer should scan
- How to properly compare elements
- Where to place the new unique element

---

# OPTIMAL APPROACH (Two Pointer)

## First Thought Intuition

Because array is sorted, all duplicates are adjacent. If I stand at one number, all its copies are right next to it. So idea: Keep one pointer for last unique number, another pointer to scan.

## Desi Mental Model

Imagine: [1,1,1,2,2,3]

We want to shift all unique values to front:
- i = where next unique number should go
- j = current scanner

Initially: i = 0 (first number is always unique), j = 1

We scan with j. If nums[j] != nums[i], it's a new number, so move it to i+1.

## Thought Process (Step by Step)

1. First element is always unique → keep it
2. Start j from index 1
3. If nums[j] != nums[i]:
   - Move i forward
   - Copy nums[j] to nums[i]
4. Continue till end
5. i + 1 = number of unique elements

## Pseudocode
```
i = 0
for j = 1 to n-1:
    if nums[j] != nums[i]:
        i = i + 1
        nums[i] = nums[j]
return i + 1
```

## Algorithm
1. Initialize i = 0 (points to last unique element)
2. Loop j from 1 to n-1:
   - If nums[j] is different from nums[i]:
     - Increment i
     - Copy nums[j] to nums[i]
3. Return i + 1 (count of unique elements)

## CODE (C++ and JavaScript)

### C++

#### V1 (Only Required Function)
```cpp
int removeDuplicates(vector<int>& nums) {
    int i = 0;   // i points to last unique element
    
    for (int j = 1; j < nums.size(); j++) {
        // If current element is different from last unique
        if (nums[j] != nums[i]) {
            i++;                // move unique pointer
            nums[i] = nums[j];  // overwrite next position
        }
    }
    
    // total unique elements = i + 1
    return i + 1;
}
```

#### V2 (Complete Program)
```cpp
#include <bits/stdc++.h>
using namespace std;

int removeDuplicates(vector<int>& nums) {
    // i points to the position of last unique element
    int i = 0;
    
    // j scans the array
    for (int j = 1; j < nums.size(); j++) {
        // If current number is different from last unique
        if (nums[j] != nums[i]) {
            i++;                // move unique pointer forward
            nums[i] = nums[j];  // place new unique number
        }
    }
    
    // i + 1 gives total unique count
    return i + 1;
}

int main() {
    vector<int> nums = {1, 1, 2, 2, 3};
    
    int k = removeDuplicates(nums);
    
    cout << "Unique count = " << k << endl;
    cout << "Array after removing duplicates:\n";
    
    for (int i = 0; i < k; i++) {
        cout << nums[i] << " ";
    }
    
    return 0;
}
```

### JavaScript

#### V1 (Only Required Function)
```javascript
var removeDuplicates = function(nums) {
    let i = 0;
    
    for (let j = 1; j < nums.length; j++) {
        if (nums[j] !== nums[i]) {
            i++;
            nums[i] = nums[j];
        }
    }
    
    return i + 1;
};
```

#### V2 (Complete Program)
```javascript
function removeDuplicates(nums) {
    let i = 0; // last unique index
    
    for (let j = 1; j < nums.length; j++) {
        if (nums[j] !== nums[i]) {
            i++;
            nums[i] = nums[j];
        }
    }
    
    return i + 1;
}

// Test
let nums = [1, 1, 2, 2, 3];
let k = removeDuplicates(nums);

console.log("Unique count:", k);
console.log("Array:", nums.slice(0, k));
```

## Time and Space Complexity
Time Complexity: O(n) - single pass through array
Space Complexity: O(1) - only using two pointers, no extra data structures

## Dry Run (All Cases)

Input: [1, 1, 2, 2, 3]

Start: i=0, nums[i]=1
- j=1: nums[1]=1, equal, skip
- j=2: nums[2]=2, not equal, i=1, nums[1]=2
Array: [1, 2, 2, 2, 3]
- j=3: nums[3]=2, equal to nums[1]=2, skip
- j=4: nums[4]=3, not equal, i=2, nums[2]=3
Array: [1, 2, 3, 2, 3]

Return i+1 = 3

Best Case: [1, 2, 3]
- i=0, j=1: 2≠1, i=1, nums[1]=2
- j=2: 3≠2, i=2, nums[2]=3
Return 3

Worst Case: [1, 1, 1, 1, 1]
- i=0, j=1: equal, skip
- j=2: equal, skip
- j=3: equal, skip
- j=4: equal, skip
Return 1

## Edge Cases
1. Single element: nums = [5]
   - Loop doesn't run (j starts at 1, size is 1)
   - Return i+1 = 1
2. Empty array: Not in constraints (min length 1)
3. All duplicates: Works as shown
4. Already unique: Works as shown
5. Negative numbers: nums = [-2, -2, -1, 0, 0, 1]
   - Works fine, maintains sorted order

## How This Approach Handles the Problem
- Uses in-place overwrite with O(1) extra space
- Maintains sorted order by exploiting sorted input
- One-pass O(n) solution
- Correctly handles all edge cases

## Why This Is Optimal

1. **Time Complexity**: O(n) - must check each element at least once
2. **Space Complexity**: O(1) - minimum possible for in-place modification
3. **Exploits constraints**: Uses sorted property to know duplicates are adjacent
4. **Simple and efficient**: Single pass with two pointers

This is optimal because:
- We cannot do better than O(n) time (must examine each element)
- We cannot use less than O(1) extra space for in-place modification
- The two-pointer technique perfectly matches the problem structure