# MODULE 1.2 — Prompt Engineering

## 34. Zero-Shot Prompting

Zero-shot prompting is the **default mode** of interacting with LLMs.

If you understand this clearly, you will know **when examples are unnecessary** and **when they become mandatory**.

---

## 1. Concept (Precise Definition)

**Zero-shot prompting** means:

> **Asking the model to perform a task without giving any examples.**

You provide:

* instructions
* constraints

But **no demonstrations**.

---

## 2. Why It’s Called “Zero-Shot”

“Shot” means **example**.

```
Zero-shot = 0 examples
Few-shot  = a few examples
```

In zero-shot, the model relies entirely on:

* its training
* instruction understanding
* role context (if provided)

---

## 3. Why Zero-Shot Usually Works

Modern LLMs are **instruction-tuned**.

They have already seen millions of patterns like:

```
Explain X
Summarize Y
Translate Z
Classify this
```

So for **common tasks**, examples are unnecessary.

---

## 4. Basic Zero-Shot Example

```js
import groq from "../../../src/utils/groqClient.js";

async function run() {
  const res = await groq.chat.completions.create({
    model: "llama-3.1-8b-instant",
    messages: [
      {
        role: "user",
        content: "Summarize binary search in one sentence.",
      },
    ],
  });

  console.log(res.choices[0].message.content);
}

await run();
```

This works because:

* summarization is a common pattern
* the instruction is clear
* no special format is required

---

## 5. Zero-Shot Works Best When

Zero-shot prompting is reliable when:

1. Task is common (summarize, explain, rewrite)
2. Output format is flexible
3. No strict structure is required
4. Minor variation is acceptable

Most beginner and learning prompts fall here.

---

## 6. Where Zero-Shot Starts to Fail

Zero-shot becomes unreliable when:

1. Output must follow strict structure
2. Classification labels must be exact
3. Domain is unusual or niche
4. Ambiguity exists in task interpretation

In these cases, the model **guesses the pattern**.

---

## 7. Failure Example (Ambiguous Zero-Shot)

```js
import groq from "../../../src/utils/groqClient.js";

async function run() {
  const res = await groq.chat.completions.create({
    model: "llama-3.1-8b-instant",
    messages: [
      {
        role: "user",
        content: "Classify this text.",
      },
    ],
  });

  console.log(res.choices[0].message.content);
}

await run();
```

Problem:

* classify into what?
* which labels?
* what format?

The model fills gaps arbitrarily.

---

## 8. Zero-Shot With Strong Instructions (Best Practice)

Zero-shot does **not** mean vague.

This is still zero-shot:

```
Classify the following text as POSITIVE or NEGATIVE.
Return only the label.
```

No examples.
Clear rules.
High success rate.

---

## 9. JavaScript Practice — Weak vs Strong Zero-Shot

```js
import groq from "../../../src/utils/groqClient.js";

async function run() {
  const weak = "Classify this review: The product is great.";
  const strong =
    "Classify the following review as POSITIVE or NEGATIVE. Return only the label.\nReview: The product is great.";

  const weakRes = await groq.chat.completions.create({
    model: "llama-3.1-8b-instant",
    messages: [{ role: "user", content: weak }],
  });

  const strongRes = await groq.chat.completions.create({
    model: "llama-3.1-8b-instant",
    messages: [{ role: "user", content: strong }],
  });

  console.log("Weak:", weakRes.choices[0].message.content);
  console.log("Strong:", strongRes.choices[0].message.content);
}

await run();
```

Observe:

* weak prompt may include explanation
* strong prompt obeys constraints

Still zero-shot.

---

## 10. Zero-Shot vs Chain-of-Thought

Important connection:

* zero-shot → no examples
* chain-of-thought → reasoning guidance

You can combine them:

```
Think carefully and give the final answer.
```

Still zero-shot.
No examples used.

---

## 11. When You Should Avoid Zero-Shot

Avoid zero-shot when:

1. Output must be machine-parsed
2. Labels must be consistent across calls
3. You are building agents
4. You are doing evaluation or scoring

These require **few-shot prompting**.

---

## 12. Mini Project — Zero-Shot Classifier

### `34-zero-shot-classifier.js`

```js
import groq from "../../../src/utils/groqClient.js";

// Simple zero-shot sentiment classifier

async function classify(text) {
  const res = await groq.chat.completions.create({
    model: "llama-3.1-8b-instant",
    temperature: 0,
    messages: [
      {
        role: "user",
        content:
          "Classify the following text as POSITIVE or NEGATIVE. Return only the label.\nText: " +
          text,
      },
    ],
  });

  return res.choices[0].message.content;
}

async function run() {
  const texts = [
    "I love this product",
    "This is the worst experience ever",
  ];

  for (const t of texts) {
    console.log(t, "→", await classify(t));
  }
}

await run();
```

This works **without any examples**.

---

## 13. Mental Rule (Use This Always)

Ask yourself:

1. Does the model already know this task?
2. Is the instruction unambiguous?
3. Is strict consistency required?

If answers are:

```
yes, yes, no
```

Zero-shot is enough.

---

## 14. Where You Are in the Roadmap

```
MODULE 1.2 — Prompt Engineering
31. Instruction prompting     Completed
32. Role prompting            Completed
33. Chain-of-thought          Completed
34. Zero-shot                 You are here
35. Few-shot                  Next
```

---

## 15. One-Line Truth (Lock It)

> **Zero-shot works when the task is obvious.
> Examples are needed only when patterns are ambiguous.**
