

# MODULE 1.2 — Prompt Engineering

## 37. JSON Mode (Structured Output Without Guessing)

This topic explains **how to force structure**.

After this:

* parsing stops breaking
* agents become reliable
* downstream code becomes simple
* “almost JSON” errors disappear

---

## 1. Concept (Precise Definition)

**JSON mode** means:

> **Constraining the model to output valid JSON that matches a predefined structure.**

The goal is **machine-readability**, not prettiness.

---

## 2. Why JSON Mode Exists

LLMs generate **free-form text** by default.

Free-form text causes problems:

* invalid JSON
* missing fields
* extra explanations
* inconsistent keys

JSON mode exists to make outputs:

```
predictable
parsable
safe for automation
```

---

## 3. JSON Mode vs “Please respond in JSON”

These are **not the same**.

### Weak approach

```
Please respond in JSON.
```

Problems:

* model may add explanations
* trailing commas
* comments
* extra text

---

### Correct approach

You must specify:

1. Exact schema
2. No extra text
3. No explanations

---

## 4. JSON Mode Without Native Enforcement (Prompt-Based)

Groq currently relies on **prompt discipline** (and optional tool schemas later).

### Example schema definition

```json
{
  "definition": "string",
  "example": "string"
}
```

You must **tell the model** this is the only allowed output.

---

## 5. JavaScript Practice — Basic JSON Output (Groq)

```js
import groq from "../../../src/utils/groqClient.js";

async function run() {
  const prompt = `
Return ONLY valid JSON.
No text outside JSON.
Schema:
{
  "definition": "string",
  "example": "string"
}

Topic: recursion
`;

  const res = await groq.chat.completions.create({
    model: "llama-3.1-8b-instant",
    temperature: 0,
    messages: [{ role: "user", content: prompt }],
  });

  console.log(res.choices[0].message.content);
}

await run();
```

Key points:

* temperature = 0 for stability
* explicit schema
* strict instruction

---

## 6. Why Temperature Matters in JSON Mode

High temperature increases:

* verbosity
* creativity
* format violations

JSON mode almost always requires:

```
temperature = 0
```

This is **non-negotiable** in production.

---

## 7. Common JSON Failure Patterns (Recognize These)

Models often fail by:

1. Adding explanations before JSON
2. Adding comments inside JSON
3. Returning arrays instead of objects
4. Misspelling keys
5. Returning partial JSON

All of these break parsers.

---

## 8. Defensive Prompt Pattern (Use This Always)

A strong JSON-mode instruction looks like this:

```
You are a function that returns JSON only.
Do not include explanations.
If you cannot comply, return an empty JSON object.
```

This reduces failure cases.

---

## 9. JavaScript Practice — Safe JSON Parse

Never trust the model blindly.

```js
function safeParse(jsonString) {
  try {
    return JSON.parse(jsonString);
  } catch {
    return null;
  }
}
```

Always assume the model **might fail**.

---

## 10. JSON Mode for Classification (Very Common)

```js
import groq from "../../../src/utils/groqClient.js";

async function run() {
  const prompt = `
Return ONLY valid JSON.
Schema:
{
  "label": "POSITIVE | NEGATIVE"
}

Text: I love this product
`;

  const res = await groq.chat.completions.create({
    model: "llama-3.1-8b-instant",
    temperature: 0,
    messages: [{ role: "user", content: prompt }],
  });

  console.log(res.choices[0].message.content);
}

await run();
```

This is safer than free-text labels.

---

## 11. JSON Mode and Agents (Critical Link)

Agents rely on JSON for:

* tool arguments
* action selection
* state transitions
* memory storage

Without JSON mode:

```
agents = unstable
```

With JSON mode:

```
agents = deterministic
```

---

## 12. When JSON Mode Is Mandatory

Use JSON mode when:

1. Output feeds into code
2. You are building agents
3. You are doing evaluation
4. You need consistency
5. You cannot afford ambiguity

Do not rely on “natural language” in these cases.

---

## 13. Mini Project — JSON Extractor

### 37-json-extractor.js

```js
import groq from "../../../src/utils/groqClient.js";

async function extract(topic) {
  const prompt = `
Return ONLY valid JSON.
Schema:
{
  "summary": "string",
  "key_points": ["string"]
}

Topic: ${topic}
`;

  const res = await groq.chat.completions.create({
    model: "llama-3.1-8b-instant",
    temperature: 0,
    messages: [{ role: "user", content: prompt }],
  });

  return JSON.parse(res.choices[0].message.content);
}

async function run() {
  const data = await extract("binary search");
  console.log(data);
}

await run();
```

This is **real-world usable output**.

---

## 14. Common Beginner Mistakes

1. Forgetting temperature = 0
2. Allowing explanations
3. Not validating JSON
4. Changing schema mid-prompt
5. Assuming the model “understands JSON”

The model follows **instructions**, not standards.

---

## 15. Where You Are in the Roadmap

```
MODULE 1.2 — Prompt Engineering
31. Instruction prompting     Completed
32. Role prompting            Completed
33. Chain-of-thought          Completed
34. Zero-shot                 Completed
35. Few-shot                  Completed
36. Safety rewriting          Completed
37. JSON mode                 You are here
38. Injection prevention      Next
```

---

## 16. One-Line Truth (Lock It)

> **If a model output must be parsed,
> free text is a bug, not a feature.**
