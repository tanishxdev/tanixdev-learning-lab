Good.
We are now entering **MODULE 1.2 — Prompt Engineering**.
From here onward, you stop *observing* models and start **controlling** them.

No emojis. Clean numbering. Same depth.

---

# MODULE 1.2 — Prompt Engineering

## 31. Instruction Prompting

This is the **foundation of all prompt engineering**.

If instruction prompting is weak:

* everything feels random
* outputs feel inconsistent
* agents behave unpredictably

If instruction prompting is strong:

* models feel reliable
* outputs become structured
* downstream techniques become easy

---

## 1. Concept (Precise Definition)

**Instruction prompting** means:

> **Explicitly telling the model what task to perform, how to perform it, and what constraints to follow.**

Without instruction prompting, the model just **continues text**.

With instruction prompting, the model **follows intent**.

---

## 2. Why Instruction Prompting Exists (WHY)

Remember from earlier modules:

An LLM does only one thing:

```
predict next token
```

It does **not know** that you want:

* an explanation
* a summary
* code
* JSON
* correctness

Unless you **instruct it clearly**.

Instruction prompting exists to:

```
reduce ambiguity
```

---

## 3. Weak Prompt vs Instruction Prompt

### Weak prompt

```
Recursion
```

What does this mean?

* definition?
* example?
* code?
* history?

The model guesses.

---

### Instruction prompt

```
Explain recursion in one sentence for a beginner.
```

Now the model knows:

1. Task: explain
2. Topic: recursion
3. Depth: beginner
4. Length: one sentence

This is **instruction prompting**.

---

## 4. Anatomy of a Good Instruction Prompt

A strong instruction prompt usually contains:

1. Action
2. Subject
3. Constraints
4. Optional format

---

### Example (annotated)

```
Explain recursion in one sentence using simple language.
```

Breakdown:

1. Action → Explain
2. Subject → recursion
3. Constraint → one sentence
4. Style → simple language

The model is now **guided**, not guessing.

---

## 5. Why Models Behave Better with Instructions

Instruction-tuned models (Groq defaults) were trained on data like:

```
Instruction → Ideal response
```

So when you give clear instructions, you activate:

```
learned instruction-following behavior
```

When you don’t, the model falls back to:

```
generic continuation
```

---

## 6. JavaScript Practice — Weak vs Strong Instruction (Groq)

```js
import groq from "../../../src/utils/groqClient.js";

async function run() {
  const weakPrompt = "Recursion";
  const strongPrompt =
    "Explain recursion in one sentence for a beginner.";

  const weakRes = await groq.chat.completions.create({
    model: "llama-3.1-8b-instant",
    messages: [{ role: "user", content: weakPrompt }],
  });

  const strongRes = await groq.chat.completions.create({
    model: "llama-3.1-8b-instant",
    messages: [{ role: "user", content: strongPrompt }],
  });

  console.log("Weak prompt output:");
  console.log(weakRes.choices[0].message.content);

  console.log("\nStrong instruction output:");
  console.log(strongRes.choices[0].message.content);
}

await run();
```

Observe:

* weak prompt → rambling or unclear
* instruction prompt → focused and precise

---

## 7. Instruction Prompting vs System Role (Important Distinction)

Instruction prompting can be done in:

1. system role
2. user role

### Rule of thumb

* **Global behavior** → system role
* **Task-specific instruction** → user role

Example:

System:

```
You are a strict programming tutor.
```

User:

```
Explain recursion in one sentence.
```

Do not mix these responsibilities.

---

## 8. Common Beginner Mistakes

1. Being vague
2. Overloading one sentence with many tasks
3. Assuming the model “knows what I want”
4. Writing polite but unclear prompts

Bad example:

```
Can you maybe try to explain recursion if possible?
```

Politeness adds tokens, not clarity.

---

## 9. Instruction Prompting Is Not About Length

Long prompt ≠ good prompt.

This is better:

```
Summarize the article in 3 bullet points.
```

Than:

```
Please carefully read the following article and then provide a very detailed and concise summary in bullet point format if possible.
```

Clear instructions beat verbose ones.

---

## 10. Mini Mental Template (Use This Always)

Before writing a prompt, mentally fill this:

```
Action:
Topic:
Constraints:
Format (optional):
```

If any of these are missing, expect instability.

---

## 11. Mini Project — Instruction Strength Tester

### `31-instruction-strength.js`

```js
import groq from "../../../src/utils/groqClient.js";

const prompts = [
  "Binary search",
  "Explain binary search",
  "Explain binary search in one sentence",
  "Explain binary search in one sentence using simple words",
];

async function run() {
  for (const prompt of prompts) {
    const res = await groq.chat.completions.create({
      model: "llama-3.1-8b-instant",
      temperature: 0.3,
      messages: [{ role: "user", content: prompt }],
    });

    console.log("\nPrompt:", prompt);
    console.log(res.choices[0].message.content);
    console.log("----");
  }
}

await run();
```

You will **see stability increase** as instructions improve.

---

## 12. Where This Fits in the Roadmap

```
MODULE 1.2 — Prompt Engineering
31. Instruction prompting     You are here
32. Role prompting            Next
33. Chain-of-thought
```

Instruction prompting is the **base layer**.

Everything else builds on top of it.

---

## 13. One-Line Truth (Lock It)

> **The model does not infer intent.
> It follows instructions — if you give them clearly.**

---

When ready, say:

**“32 next — Role prompting”**

Next we will combine:

* instruction prompting
* role hierarchy
* behavior control

We continue forward.
