# 0 First: the BIG picture

Think of GenAI like this:

```
MODEL  →  wrapped by SDK  →  used by AGENT  →  inside APPLICATION
```

Everything is one of these layers, renamed.

---

# 1 What is an LLM (Large Language Model)?

### Simple definition (real, not marketing)

An LLM is a statistical model trained on massive text data to predict the next token (word piece) given previous tokens.

That’s it.

No thinking.
No consciousness.
No memory (by default).

---

### Analogy (BEST one)

Think of LLM as:

A super-advanced autocomplete engine

Just like your phone keyboard predicts next word —
LLM predicts next token, but at insane scale.

---

### Internally (high level)

```
Text → Tokenizer → Numbers
Numbers → Neural Network (Transformer)
Transformer → Probability of next token
Repeat → until answer completes
```

---

### Important truth

LLMs do not:

• know facts
• reason like humans
• remember past chats automatically

They only:

predict next token based on patterns learned during training

---

### Examples of LLMs

• Gemini
• GPT-4 / GPT-4.1
• Claude
• LLaMA
• Mistral

---

### Where LLM fits in your roadmap

```
MODULE 1 — GenAI Basics
21–30 (LLM fundamentals)
```

LLM = foundation of everything else

---

# 2 What is a “Model”?

This is subtle but important.

### Definition

A model is a trained instance of an LLM with specific size, training data, and optimization goals.

---

### Example

LLM family: Gemini

Models:

• gemini-2.5-pro → high reasoning
• gemini-2.5-flash → fast & cheap
• gemini-2.5-flash-lite → ultra-cheap

Same brain family, different tuning.

---

### Analogy

Think of:

```
Car brand = LLM family
Car models = specific models
```

Toyota (LLM)
→ Corolla, Fortuner, Supra (models)

---

### Internally

Different models differ by:

• parameter count
• context window
• training style
• cost per token
• latency

---

### Roadmap relevance

```
MODULE 1
24. Model types
29. Model versions
30. Pricing
```

---

# 3 What is GenAI (Generative AI)?

### Definition (precise)

GenAI refers to systems that generate new content (text, images, audio, video) instead of just classifying or predicting labels.

---

### GenAI ≠ LLM only

GenAI includes:

• Text generation (LLMs)
• Image generation (Diffusion models)
• Audio generation
• Video generation

---

### Analogy

Traditional ML:

“Is this spam or not?”

GenAI:

“Write me a professional email apologizing for delay”

---

### Internally

GenAI systems use:

• Transformers (text)
• Diffusion models (images/video)
• Audio models

---

### Roadmap relevance

Your entire roadmap is GenAI-focused.

---

# 4 What is an SDK?

You used one already.

### Definition

An SDK (Software Development Kit) is a wrapper that makes APIs easier to use in a programming language.

---

### Example

```js
ai.models.generateContent(...)
```

Instead of:

```http
POST https://generativelanguage.googleapis.com/v1/models/...
```

---

### Analogy

SDK is like:

Remote control for a TV

You don’t manually press circuits.
You press buttons.

---

### Internally

SDK handles:

• HTTP requests
• Headers
• Auth
• JSON parsing
• Errors

---

### Roadmap relevance

```
MODULE 2 — API Clients
```

---

# 5 What is an Agent? (VERY IMPORTANT)

### Simple definition

An agent is an LLM + instructions + tools + memory + loop.

LLM alone is passive.
Agent is active.

---

### Core statement

LLM alone is passive.
Agent is active.

---

### What “LLM is passive” actually means

#### Definition

An LLM by itself:

• waits for input
• generates one response
• stops
• does nothing else

It cannot:
• decide next step
• call APIs
• read files
• retry
• verify
• remember long-term

---

#### Example (pure LLM)

```js
response = LLM("Explain binary search");
```

What happens:

```
Input → LLM → Output → END
```

No loop. No action.

---

#### Analogy

LLM alone is like:

A very smart person locked in a room with no hands

They can talk, but they can’t do anything.

---

#### Internally

```
Prompt
 ↓
Token prediction
 ↓
Text output
 ↓
STOP
```

There is no concept of “goal completion”.

---

### What “Agent is active” actually means

#### Definition

An agent is:

LLM + goal + tools + memory + control loop

This makes it capable of acting, not just answering.

---

#### Example (agent)

User goal:

"Summarize latest news on AI startups"

Agent flow:

```
Think → search web → read articles → summarize → respond
```

Multiple steps.

---

#### Analogy

Agent is like:

A smart employee

Employee:
• understands goal
• uses tools
• checks output
• retries if needed
• stops when done

---

### Visual difference (VERY IMPORTANT)

#### Passive LLM

```
User → LLM → Answer → End
```

#### Active Agent

```
User goal
   ↓
LLM (plan)
   ↓
Tool call
   ↓
Result
   ↓
LLM (think again)
   ↓
More actions
   ↓
Final answer
```

---

### Concrete code-level difference (JS)

#### LLM-only (passive)

```js
const res = await ai.models.generateContent({
  model: "gemini-2.5-flash",
  contents: "Find best JS frameworks"
});

console.log(res.text);
```

One shot. Done.

---

#### Agent (active)

```js
while (!goalComplete) {
  const thought = await llm(planPrompt);
  
  if (thought.action === "search") {
    const result = await webSearch(thought.query);
    memory.push(result);
  }

  if (thought.action === "summarize") {
    answer = await llm(summaryPrompt(memory));
    goalComplete = true;
  }
}
```

LLM drives actions.

---

### Why LLMs are designed passive (on purpose)

Important insight.

LLMs are passive because:

• safer
• predictable
• cheaper
• controllable

Autonomy without control = chaos.

That’s why agents are built on top, not baked inside models.

---

### Where “activity” actually lives

This is crucial.

Agents are NOT inside the model

They live in:

• your backend code
• LangChain
• LangGraph
• ADKs

The LLM only:

suggests next action

Your code:

executes it

---

### Real-world examples you already know

| System             | Passive / Active |
| ------------------ | ---------------- |
| ChatGPT (no tools) | Passive          |
| ChatGPT with tools | Active           |
| Cursor AI          | Agent            |
| Devin              | Agent            |
| AutoGPT            | Agent            |
| Google Search AI   | Agentic system   |

---

### Why this matters for your roadmap

Your roadmap progression makes sense because:

```
LLM fundamentals
   ↓
Prompting
   ↓
API clients
   ↓
RAG
   ↓
Agents
   ↓
LangGraph
```

You must understand passive → active transition.

---

### One-line takeaway (lock it)

LLM answers questions.
Agents complete tasks.

---

### Analogy (best one)

LLM = brain
Agent = employee

Employee:
• thinks
• uses tools
• checks results
• repeats steps

---

### Internally (high-level)

```
User goal
  ↓
LLM thinks (plan)
  ↓
Calls tool (API / DB / file)
  ↓
Gets result
  ↓
LLM thinks again
  ↓
Repeat until done
```

---

### Key difference from simple prompt

Prompt:

```
Ask once → answer once
```

Agent:

```
Plan → act → observe → think → act → stop
```

---

### Roadmap relevance

```
MODULE 4 — Agents
73–87
```

This is 2025+ most important skill, you’re right.

---

# 6 What is Agentic AI / Agentic AG?

### Market term explanation

Agentic AI = systems built around agents that can act autonomously over multiple steps.

It’s NOT a new technology.
It’s a design pattern.

---

### Analogy

Normal chatbot:

“Answer this question”

Agentic system:

“Complete this task even if it takes 10 steps”

---

### Examples

• AutoGPT
• Devin
• Cursor agent
• ChatGPT tools mode

---

### Internal difference

| LLM             | Agentic AI      |
| --------------- | --------------- |
| Single response | Multi-step loop |
| No tools        | Tool calling    |
| Stateless       | Has memory      |
| Passive         | Goal-driven     |

---

### Roadmap relevance

```
MODULE 4
MODULE 8 (LangGraph)
MODULE 9 (MCP)
```

---

# 7 What is an ADK? (Agent Dev Kit)

### Definition

An ADK is a framework for building agents more safely and structurally.

Just like:

• React for UI
• Express for backend

ADK is for agents.

---

### Examples

• LangChain
• LangGraph
• OpenAI Assistants
• Google Agent frameworks

---

### Why ADKs exist

Because raw agents are:

• fragile
• loop forever
• unsafe
• hard to debug

---

### Roadmap relevance

```
MODULE 7 — LangChain
MODULE 8 — LangGraph
```

---

# 8 What is RAG?

You’ll use this heavily.

### Definition

RAG = Retrieval + LLM generation

LLM alone hallucinates.
RAG grounds it with real data.

---

### Analogy

LLM without RAG:

Student answering from memory

LLM with RAG:

Student allowed to open textbook before answering

---

### Internal flow

```
User query
 ↓
Search vector DB
 ↓
Relevant documents
 ↓
Injected into prompt
 ↓
LLM generates grounded answer
```

---

### Roadmap relevance

```
MODULE 3 — RAG
```

---

# 9 What is MCP (Model Context Protocol)?

Advanced, but you included it correctly.

### Definition

MCP is a standardized way for models to interact with external tools, OS, editors, files, and apps.

Think USB for AI tools.

---

### Analogy

Before USB:
• every device custom port

After USB:
• one standard

MCP = standard tool interface for AI

---

### Roadmap relevance

```
MODULE 9 — MCP
```

---

# 10 Final mental map (lock this)

```
LLM → base intelligence
Model → specific tuned version
SDK → developer interface
GenAI → content generation category
Agent → LLM + tools + loop
Agentic AI → system built around agents
ADK → framework to build agents
RAG → external knowledge injection
MCP → standard tool interface
```

---
