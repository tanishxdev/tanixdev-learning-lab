# **CONSISTENT HASHING**

---

# **1. WHY DO WE NEED HASHING? (THE ORIGINAL PROBLEM)**

### **Problem Setup**

Your application has:

* Many users
* Lots of data
* One database is becoming a bottleneck

So you decide to scale **horizontally** → add more database servers.

Example:
Instead of 1 DB → you add **3 DBs**:

```
DB0   DB1   DB2
```

Now the question:

> **How will we divide user data across these 3 databases?**

We need a rule that:

* Places a user's data on a specific DB
* Allows us to find that data later (lookup)
* Distributes load evenly

---

# **2. HASH FUNCTION (THE FIRST IDEA)**

We try a basic function:

```
index = userID mod numberOfServers
```

Example with 3 servers:

```
user 1 → 1 mod 3 = 1  → DB1  
user 2 → 2 mod 3 = 2  → DB2  
user 3 → 3 mod 3 = 0  → DB0  
user 4 → 4 mod 3 = 1  → DB1  
user 5 → 5 mod 3 = 2  → DB2
```

### Properties of a Good Hash Function

A hash function must be:

1. **Deterministic**
   Same input → always same output.

2. **Fixed size output**
   It maps large space to small fixed indexes.

3. **One-way**
   You cannot reverse it to get input back.

4. **Even load distribution**
   All servers should get almost equal data.

This works well **as long as the number of servers stays constant.**

---

# **3. THE BIG PROBLEM: SERVER ADDED / REMOVED**

Let’s say initially servers = 3
You stored all your users using:

```
index = ID mod 3
```

Now suppose you add **one more server** (server count = 4)

You must now compute:

```
index = ID mod 4
```

### What happens?

Try recalculating positions:

| UserID | Old (mod 3) | New (mod 4) | Moves? |
| ------ | ----------- | ----------- | ------ |
| 1      | 1           | 1           | no     |
| 2      | 2           | 2           | no     |
| 3      | 0           | 3           | YES    |
| 4      | 1           | 0           | YES    |
| 5      | 2           | 1           | YES    |

**3 out of 5 keys moved.**

For large systems → millions of keys will move.
This creates huge **data movement**, downtime, and instability.

Similarly, if a server goes down → again massive reshuffling.

So:

> **Hashing using mod N breaks when N changes.**

This is the **core problem** consistent hashing solves.

---

# **4. CONSISTENT HASHING — THE FIX**

Consistent Hashing introduces a beautiful concept:

# **THE HASH RING**

Imagine values from 0 to M arranged on a circle:

```
      12
   11    1
 10        2
 9          3
 8          4
   7     5
      6
```

Steps:

---

## **Step 1 — Hash Servers onto the Ring**

Each server is hashed using a hash function:

```
serverHash = Hash(serverID)
```

Suppose:

```
Server A → 2
Server B → 5
Server C → 9
```

Place them on the ring:

```
      (A)
12           2
9 (C)      5 (B)
```

---

## **Step 2 — Hash Keys (User IDs) onto the Same Ring**

Example:

```
userHash = Hash(userID)
```

Suppose user hashes are:

```
1, 3, 4, 7, 10
```

Place these positions on ring.

---

## **Step 3 — CLOCKWISE SEARCH RULE**

For each key:

> **Place key on the first server you find when moving clockwise.**

Example:

```
Key at 1 → next server is A → goes to Server A  
Key at 3 → next server is B → goes to Server B  
Key at 4 → next server is B → goes to Server B  
Key at 7 → next server is C → goes to Server C  
Key at 10 → next server is A → goes to Server A (wrap around)
```

This creates balanced distribution **independent of number of servers**.

---

# **5. WHY IS CONSISTENT HASHING MAGIC?**

## **Case 1: Adding a New Server**

Say a new server D hashes to position 12.

Only keys between **previous server (C at 9)** → **new server (12)** need movement.

Only keys in this slice move:

```
(9 → 12)
```

Everything else stays untouched.

> **Only a fraction of keys move, not all.**

---

## **Case 2: Removing a Server**

If Server B (at position 5) dies:

Only keys between:

```
(previous server at 2) → (next server at 9)
```

need to be moved to 9.

Again → only a small range affected.

---

# **6. BENEFIT SUMMARY**

### **1. Minimal Data Movement**

Only keys in the affected interval move.

Old hashing:
Almost all keys move.

Consistent hashing:
Only keys between two server points.

---

### **2. Easy Horizontal Scaling**

Add or remove servers without reshuffling entire dataset.

---

### **3. Even Load Distribution**

Most of the time keys distribute uniformly across the ring.

---

# **7. PROBLEM INSIDE CONSISTENT HASHING — LOAD IMBALANCE**

What if two servers are very close on the ring?

Example:

```
Server A at 2  
Server B at 3  
Server C at 9
```

Huge chunk (3 → 9) goes to C → heavy load.
Tiny area (2 → 3) has little data.

> **Solution → VIRTUAL NODES**

Every server appears multiple times on the ring:

Example:

```
Server A → positions 2, 5, 11  
Server B → positions 3, 7, 10  
Server C → positions 4, 8, 9
```

This spreads load uniformly.

Virtual nodes = pointers back to the same real server.

---

# **8. HOW TO CALCULATE AFFECTED RANGE WHEN A SERVER IS ADDED**

If a new server is at position X:

1. Move anticlockwise to find the previous server position P
2. All keys in range (P → X) move to the new server
3. Others remain untouched

Example:

New server at 12, previous server at 9
Only keys in 10, 11, 12 move.

---

# **9. REAL-WORLD USE CASES**

Consistent hashing is used in:

* Amazon DynamoDB
* Apache Cassandra
* Akka
* Redis Cluster
* CDN caching
* Distributed caching systems
* Distributed key/value stores

Because all of these need:

* Scalable systems
* Quick addition/removal of nodes
* Minimal data movement

---

# **10. FINAL RECAP (VERY SHORT)**

**Consistent Hashing solves one problem:**

> When servers change, don’t move all data.
> Move only a small amount.

It achieves this by:

1. Mapping servers + keys onto a ring
2. Using clockwise lookup
3. Moving only the keys in affected interval
4. Adding virtual nodes for perfect load balancing

This makes distributed systems scalable, stable, and fast.

---

## Further Reading
* [Consistent Hashing on ByteByteGo](https://bytebytego.com/courses/system-design-interview/design-consistent-hashing)